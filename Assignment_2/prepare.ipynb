{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\X\n",
      "[nltk_data]     Warrior\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\X\n",
      "[nltk_data]     Warrior\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    # Lowercase all text\n",
    "    df['message'] = df['message'].str.lower()\n",
    "\n",
    "    # Remove punctuation\n",
    "    df['message'] = df['message'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "\n",
    "    # Remove numbers\n",
    "    df['message'] = df['message'].apply(lambda x: re.sub(r'\\d+', '', x))\n",
    "\n",
    "    # Tokenize the text\n",
    "    df['message'] = df['message'].apply(lambda x: x.split())\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    df['message'] = df['message'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "    # Lemmatize the text\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    df['message'] = df['message'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "\n",
    "    # Join tokens back into a single string\n",
    "    df['message'] = df['message'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "    # Encode labels \n",
    "    df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "    # Drop duplicates\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def store_data(df, seed=42):\n",
    "    train, test = train_test_split(df, test_size=0.2, random_state=seed)\n",
    "    train, val = train_test_split(train, test_size=0.1, random_state=seed)\n",
    "    \n",
    "    train.to_csv('train.csv', index=False)\n",
    "    val.to_csv('validation.csv', index=False)\n",
    "    test.to_csv('test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('SMSSpamCollection.txt', sep='\\t', names=['label', 'message'])\n",
    "data = preprocess_data(data)\n",
    "data.to_csv(\"raw_data.csv\", index=False)\n",
    "store_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add train.csv.dvc test.csv.dvc raw_data.csv.dvc .gitignore validation.csv.dvc\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⠋ Checking graph\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 2a22d68] Added raw and split datasets\n",
      " 8 files changed, 30 insertions(+)\n",
      " create mode 100644 .dvc/.gitignore\n",
      " create mode 100644 .dvc/config\n",
      " create mode 100644 .dvcignore\n",
      " create mode 100644 Assignment_2/.gitignore\n",
      " create mode 100644 Assignment_2/raw_data.csv.dvc\n",
      " create mode 100644 Assignment_2/test.csv.dvc\n",
      " create mode 100644 Assignment_2/train.csv.dvc\n",
      " create mode 100644 Assignment_2/validation.csv.dvc\n"
     ]
    }
   ],
   "source": [
    "!dvc add raw_data.csv train.csv validation.csv test.csv\n",
    "!git add raw_data.csv.dvc train.csv.dvc validation.csv.dvc test.csv.dvc .gitignore\n",
    "!git commit -m \"Added raw and split datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data(data, seed=57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add test.csv.dvc validation.csv.dvc train.csv.dvc\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⠋ Checking graph\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 3e84669] Updated train/validation/test split with new random seed\n",
      " 4 files changed, 6 insertions(+), 5580 deletions(-)\n",
      " delete mode 100644 Assignment 1/SMSSpamCollection.txt\n"
     ]
    }
   ],
   "source": [
    "!dvc add train.csv validation.csv test.csv\n",
    "!git commit -am \"Updated train/validation/test split with new random seed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: switching to 'HEAD~1'.\n",
      "\n",
      "You are in 'detached HEAD' state. You can look around, make experimental\n",
      "changes and commit them, and you can discard any commits you make in this\n",
      "state without impacting any branches by switching back to a branch.\n",
      "\n",
      "If you want to create a new branch to retain commits you create, you may\n",
      "do so (now or later) by using -c with the switch command. Example:\n",
      "\n",
      "  git switch -c <new-branch-name>\n",
      "\n",
      "Or undo this operation with:\n",
      "\n",
      "  git switch -\n",
      "\n",
      "Turn off this advice by setting config variable advice.detachedHead to false\n",
      "\n",
      "HEAD is now at 2a22d68 Added raw and split datasets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M       validation.csv\n",
      "M       test.csv\n",
      "M       train.csv\n"
     ]
    }
   ],
   "source": [
    "!git checkout HEAD~1  \n",
    "!dvc checkout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution in train.csv:\n",
      "label\n",
      "0    3228\n",
      "1     426\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Distribution in validation.csv:\n",
      "label\n",
      "0    357\n",
      "1     49\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Distribution in test.csv:\n",
      "label\n",
      "0    898\n",
      "1    117\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for filename in [\"train.csv\", \"validation.csv\", \"test.csv\"]:\n",
    "    df = pd.read_csv(filename)\n",
    "    print(f\"Distribution in {filename}:\")\n",
    "    print(df[\"label\"].value_counts(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your branch is ahead of 'origin/main' by 2 commits.\n",
      "  (use \"git push\" to publish your local commits)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Previous HEAD position was 2a22d68 Added raw and split datasets\n",
      "Switched to branch 'main'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M       validation.csv\n",
      "M       train.csv\n",
      "M       test.csv\n"
     ]
    }
   ],
   "source": [
    "!git checkout main  \n",
    "!dvc checkout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution in train.csv:\n",
      "label\n",
      "0    3233\n",
      "1     421\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Distribution in validation.csv:\n",
      "label\n",
      "0    357\n",
      "1     49\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Distribution in test.csv:\n",
      "label\n",
      "0    893\n",
      "1    122\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for filename in [\"train.csv\", \"validation.csv\", \"test.csv\"]:\n",
    "    df = pd.read_csv(filename)\n",
    "    print(f\"Distribution in {filename}:\")\n",
    "    print(df[\"label\"].value_counts(), \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
